{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bmacs/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"SMSSpamCollection.tsv\", sep='\\t')\n",
    "data.columns = ['label', 'body_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_punct(text):\n",
    "    count = sum([1 for char in text if char in string.punctuation])\n",
    "    return round(count/(len(text) - text.count(\" \")), 3)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['body_len'] = data['body_text'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "data['punct%'] = data['body_text'].apply(lambda x: count_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "X_tfidf = tfidf_vect.fit_transform(data['body_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>8094</th>\n",
       "      <th>8095</th>\n",
       "      <th>8096</th>\n",
       "      <th>8097</th>\n",
       "      <th>8098</th>\n",
       "      <th>8099</th>\n",
       "      <th>8100</th>\n",
       "      <th>8101</th>\n",
       "      <th>8102</th>\n",
       "      <th>8103</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 8106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_len  punct%    0    1    2    3    4    5    6    7  ...   8094  8095  \\\n",
       "0       128     4.7  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "1        49     4.1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "2        62     3.2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "3        28     7.1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "4       135     4.4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "\n",
       "   8096  8097  8098  8099  8100  8101  8102  8103  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 8106 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features = pd.concat([data['body_len'], data['punct%'], pd.DataFrame(X_tfidf.toarray())], axis=1)\n",
    "X_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__abstractmethods__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_abc_cache', '_abc_negative_cache', '_abc_negative_cache_version', '_abc_registry', '_estimator_type', '_get_param_names', '_make_estimator', '_set_oob_score', '_validate_X_predict', '_validate_estimator', '_validate_y_class_weight', 'apply', 'decision_path', 'feature_importances_', 'fit', 'get_params', 'predict', 'predict_log_proba', 'predict_proba', 'score', 'set_params']\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(dir(RandomForestClassifier))\n",
    "print(RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "JoblibMemoryError",
     "evalue": "JoblibMemoryError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7f038491f5d0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/bmacs/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/bmacs/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/bmacs/.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f038491f5d0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/bmacs/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/bmacs/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/bmacs/.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         self.io_loop = ioloop.IOLoop.current()\n    477         try:\n--> 478             self.io_loop.start()\n        self.io_loop.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    479         except KeyboardInterrupt:\n    480             pass\n    481 \n    482 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"cross_val_score(rf, X_features, data['label'], cv=k_fold, scoring='accuracy', n_jobs=-1)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 5, 28, 18, 38, 30, 38732, tzinfo=tzutc()), 'msg_id': '9de4633913f240698a935f06d57ef25b', 'msg_type': 'execute_request', 'session': 'c493ad538f5f4b308ca3a30afff2e601', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '9de4633913f240698a935f06d57ef25b', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'c493ad538f5f4b308ca3a30afff2e601']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"cross_val_score(rf, X_features, data['label'], cv=k_fold, scoring='accuracy', n_jobs=-1)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 5, 28, 18, 38, 30, 38732, tzinfo=tzutc()), 'msg_id': '9de4633913f240698a935f06d57ef25b', 'msg_type': 'execute_request', 'session': 'c493ad538f5f4b308ca3a30afff2e601', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '9de4633913f240698a935f06d57ef25b', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'c493ad538f5f4b308ca3a30afff2e601'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"cross_val_score(rf, X_features, data['label'], cv=k_fold, scoring='accuracy', n_jobs=-1)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 5, 28, 18, 38, 30, 38732, tzinfo=tzutc()), 'msg_id': '9de4633913f240698a935f06d57ef25b', 'msg_type': 'execute_request', 'session': 'c493ad538f5f4b308ca3a30afff2e601', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '9de4633913f240698a935f06d57ef25b', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"cross_val_score(rf, X_features, data['label'], cv=k_fold, scoring='accuracy', n_jobs=-1)\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"cross_val_score(rf, X_features, data['label'], cv=k_fold, scoring='accuracy', n_jobs=-1)\"\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"cross_val_score(rf, X_features, data['label'], cv=k_fold, scoring='accuracy', n_jobs=-1)\",), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"cross_val_score(rf, X_features, data['label'], cv=k_fold, scoring='accuracy', n_jobs=-1)\",)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"cross_val_score(rf, X_features, data['label'], cv=k_fold, scoring='accuracy', n_jobs=-1)\", store_history=True, silent=False, shell_futures=True)\n   2723                 self.displayhook.exec_result = result\n   2724 \n   2725                 # Execute the user code\n   2726                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2727                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2728                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2729                 \n   2730                 self.last_execution_succeeded = not has_raised\n   2731                 self.last_execution_result = result\n   2732 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name='<ipython-input-22-c17948fdf9b6>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f034248ee10, executi..._before_exec=None error_in_exec=None result=None>)\n   2851                     return True\n   2852 \n   2853             for i, node in enumerate(to_run_interactive):\n   2854                 mod = ast.Interactive([node])\n   2855                 code = compiler(mod, cell_name, \"single\")\n-> 2856                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f0341fba6f0, file \"<ipython-input-22-c17948fdf9b6>\", line 1>\n        result = <ExecutionResult object at 7f034248ee10, executi..._before_exec=None error_in_exec=None result=None>\n   2857                     return True\n   2858 \n   2859             # Flush softspace\n   2860             if softspace(sys.stdout, 0):\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f0341fba6f0, file \"<ipython-input-22-c17948fdf9b6>\", line 1>, result=<ExecutionResult object at 7f034248ee10, executi..._before_exec=None error_in_exec=None result=None>)\n   2905         outflag = True  # happens in more places, so it's easier as default\n   2906         try:\n   2907             try:\n   2908                 self.hooks.pre_run_code_hook()\n   2909                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2910                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f0341fba6f0, file \"<ipython-input-22-c17948fdf9b6>\", line 1>\n        self.user_global_ns = {'In': ['', 'import nltk\\nimport pandas as pd\\nimport re\\nfrom s...raction.text import TfidfVectorizer\\nimport string', \"stopwords = nltk.corpus.stopwords.words('english')\\nps = nltk.PorterStemmer()\", 'data = pd.read_csv(\"SMSSpamCollection.tsv\", sep=\\'\\\\t\\')\\ndata.columns = [\\'label\\', \\'body_text\\']', 'def count_punct(text):\\n    count = sum([1 for ch...round(count/(len(text) - text.count(\" \")), 3)*100', \"data['body_len'] = data['body_text'].apply(lambd...ata['body_text'].apply(lambda x: count_punct((x))\", \"data['body_len'] = data['body_text'].apply(lambd...data['body_text'].apply(lambda x: count_punct(x))\", 'def clean_text(text):\\n    text = \"\".join([word.l... tokens if word not in stopwords]\\n    return text', \"tfidf_vect = TfidfVectorizer(analyzer=clean_text...idf = tfidf_vect.fit_transform(data['body_text'])\", \"X_features = pd.concat([data['body_len'], data['...me(X_tfidf.toarray())], axis=1)\\nX_features.head()\", 'from sklearn.ensemble import RandomForestClassifier', 'print(dir(RandomForestClassifier))\\nprint(RandomForestClassifier())', 'from sklearn.model_selection import KFold, cross_val_score', 'rf = RandomForestClassifier(n_jobs=-1)', 'k_fold = KFold(n_splits=5)', \"cross_val_score(rf, X_features, data['label'], cv=k_fold, scoring='accuracy', n_jobs=-1)\", 'k_fold = KFold(n_splits=5)', \"cross_val_score(rf, X_features, data['label'], cv=k_fold, scoring='accuracy', n_jobs=-1)\", 'from sklearn.model_selection import KFold, cross_val_score', 'rf = RandomForestClassifier(n_jobs=-1)', ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'Out': {9:    body_len  punct%    0    1    2    3    4    ... 0.0   0.0   0.0   0.0  \n\n[5 rows x 8106 columns]}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'TfidfVectorizer': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, 'X_features':       body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], 'X_tfidf': <5567x8104 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, '_':    body_len  punct%    0    1    2    3    4    ... 0.0   0.0   0.0   0.0  \n\n[5 rows x 8106 columns], '_9':    body_len  punct%    0    1    2    3    4    ... 0.0   0.0   0.0   0.0  \n\n[5 rows x 8106 columns], '__': '', ...}\n        self.user_ns = {'In': ['', 'import nltk\\nimport pandas as pd\\nimport re\\nfrom s...raction.text import TfidfVectorizer\\nimport string', \"stopwords = nltk.corpus.stopwords.words('english')\\nps = nltk.PorterStemmer()\", 'data = pd.read_csv(\"SMSSpamCollection.tsv\", sep=\\'\\\\t\\')\\ndata.columns = [\\'label\\', \\'body_text\\']', 'def count_punct(text):\\n    count = sum([1 for ch...round(count/(len(text) - text.count(\" \")), 3)*100', \"data['body_len'] = data['body_text'].apply(lambd...ata['body_text'].apply(lambda x: count_punct((x))\", \"data['body_len'] = data['body_text'].apply(lambd...data['body_text'].apply(lambda x: count_punct(x))\", 'def clean_text(text):\\n    text = \"\".join([word.l... tokens if word not in stopwords]\\n    return text', \"tfidf_vect = TfidfVectorizer(analyzer=clean_text...idf = tfidf_vect.fit_transform(data['body_text'])\", \"X_features = pd.concat([data['body_len'], data['...me(X_tfidf.toarray())], axis=1)\\nX_features.head()\", 'from sklearn.ensemble import RandomForestClassifier', 'print(dir(RandomForestClassifier))\\nprint(RandomForestClassifier())', 'from sklearn.model_selection import KFold, cross_val_score', 'rf = RandomForestClassifier(n_jobs=-1)', 'k_fold = KFold(n_splits=5)', \"cross_val_score(rf, X_features, data['label'], cv=k_fold, scoring='accuracy', n_jobs=-1)\", 'k_fold = KFold(n_splits=5)', \"cross_val_score(rf, X_features, data['label'], cv=k_fold, scoring='accuracy', n_jobs=-1)\", 'from sklearn.model_selection import KFold, cross_val_score', 'rf = RandomForestClassifier(n_jobs=-1)', ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'Out': {9:    body_len  punct%    0    1    2    3    4    ... 0.0   0.0   0.0   0.0  \n\n[5 rows x 8106 columns]}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'TfidfVectorizer': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, 'X_features':       body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], 'X_tfidf': <5567x8104 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, '_':    body_len  punct%    0    1    2    3    4    ... 0.0   0.0   0.0   0.0  \n\n[5 rows x 8106 columns], '_9':    body_len  punct%    0    1    2    3    4    ... 0.0   0.0   0.0   0.0  \n\n[5 rows x 8106 columns], '__': '', ...}\n   2911             finally:\n   2912                 # Reset our crash handler in place\n   2913                 sys.excepthook = old_excepthook\n   2914         except SystemExit as e:\n\n...........................................................................\n/home/bmacs/BigData/Week9/<ipython-input-22-c17948fdf9b6> in <module>()\n----> 1 cross_val_score(rf, X_features, data['label'], cv=k_fold, scoring='accuracy', n_jobs=-1)\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in cross_val_score(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=      body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], y=0       spam\n1        ham\n2        ham\n3        ...     ham\nName: label, Length: 5567, dtype: object, groups=None, scoring='accuracy', cv=KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')\n    316     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n    317                                 scoring={'score': scorer}, cv=cv,\n    318                                 return_train_score=False,\n    319                                 n_jobs=n_jobs, verbose=verbose,\n    320                                 fit_params=fit_params,\n--> 321                                 pre_dispatch=pre_dispatch)\n        pre_dispatch = '2*n_jobs'\n    322     return cv_results['test_score']\n    323 \n    324 \n    325 def _fit_and_score(estimator, X, y, scorer, train, test, verbose,\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=      body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], y=0       spam\n1        ham\n2        ham\n3        ...     ham\nName: label, Length: 5567, dtype: object, groups=None, scoring={'score': make_scorer(accuracy_score)}, cv=KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False)\n    190     scores = parallel(\n    191         delayed(_fit_and_score)(\n    192             clone(estimator), X, y, scorers, train, test, verbose, None,\n    193             fit_params, return_train_score=return_train_score,\n    194             return_times=True)\n--> 195         for train, test in cv.split(X, y, groups))\n        cv.split = <bound method _BaseKFold.split of KFold(n_splits=5, random_state=None, shuffle=False)>\n        X =       body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns]\n        y = 0       spam\n1        ham\n2        ham\n3        ...     ham\nName: label, Length: 5567, dtype: object\n        groups = None\n    196 \n    197     if return_train_score:\n    198         train_scores, test_scores, fit_times, score_times = zip(*scores)\n    199         train_scores = _aggregate_score_dicts(train_scores)\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object cross_validate.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nMemoryError                                        Mon May 28 14:38:33 2018\nPID: 10579                   Python 3.6.4: /home/bmacs/anaconda3/bin/python\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False),       body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], 0       spam\n1        ham\n2        ham\n3        ...     ham\nName: label, Length: 5567, dtype: object, {'score': make_scorer(accuracy_score)}, array([   0,    1,    2, ..., 5564, 5565, 5566]), array([2228, 2229, 2230, ..., 3338, 3339, 3340]), 0, None, None), {'return_times': True, 'return_train_score': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False),       body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], 0       spam\n1        ham\n2        ham\n3        ...     ham\nName: label, Length: 5567, dtype: object, {'score': make_scorer(accuracy_score)}, array([   0,    1,    2, ..., 5564, 5565, 5566]), array([2228, 2229, 2230, ..., 3338, 3339, 3340]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=      body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], y=0       spam\n1        ham\n2        ham\n3        ...     ham\nName: label, Length: 5567, dtype: object, scorer={'score': make_scorer(accuracy_score)}, train=array([   0,    1,    2, ..., 5564, 5565, 5566]), test=array([2228, 2229, 2230, ..., 3338, 3339, 3340]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    422     if parameters is not None:\n    423         estimator.set_params(**parameters)\n    424 \n    425     start_time = time.time()\n    426 \n--> 427     X_train, y_train = _safe_split(estimator, X, y, train)\n        X_train = undefined\n        y_train = undefined\n        estimator = RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False)\n        X =       body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns]\n        y = 0       spam\n1        ham\n2        ham\n3        ...     ham\nName: label, Length: 5567, dtype: object\n        train = array([   0,    1,    2, ..., 5564, 5565, 5566])\n    428     X_test, y_test = _safe_split(estimator, X, y, test, train)\n    429 \n    430     is_multimetric = not callable(scorer)\n    431     n_scorers = len(scorer.keys()) if is_multimetric else 1\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _safe_split(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=      body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], y=0       spam\n1        ham\n2        ham\n3        ...     ham\nName: label, Length: 5567, dtype: object, indices=array([   0,    1,    2, ..., 5564, 5565, 5566]), train_indices=None)\n    195         if train_indices is None:\n    196             X_subset = X[np.ix_(indices, indices)]\n    197         else:\n    198             X_subset = X[np.ix_(indices, train_indices)]\n    199     else:\n--> 200         X_subset = safe_indexing(X, indices)\n        X_subset = undefined\n        X =       body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns]\n        indices = array([   0,    1,    2, ..., 5564, 5565, 5566])\n    201 \n    202     if y is not None:\n    203         y_subset = safe_indexing(y, indices)\n    204     else:\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py in safe_indexing(X=      body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], indices=array([   0,    1,    2, ..., 5564, 5565, 5566]))\n    144     if hasattr(X, \"iloc\"):\n    145         # Work-around for indexing with read-only indices in pandas\n    146         indices = indices if indices.flags.writeable else indices.copy()\n    147         # Pandas Dataframes and Series\n    148         try:\n--> 149             return X.iloc[indices]\n        X.iloc = <pandas.core.indexing._iLocIndexer object>\n        indices = array([   0,    1,    2, ..., 5564, 5565, 5566])\n    150         except ValueError:\n    151             # Cython typed memoryviews internally used in pandas do not support\n    152             # readonly buffers.\n    153             warnings.warn(\"Copying input dataframe for slicing.\",\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self=<pandas.core.indexing._iLocIndexer object>, key=array([   0,    1,    2, ..., 5564, 5565, 5566]))\n   1368         else:\n   1369             # we by definition only have the 0th axis\n   1370             axis = self.axis or 0\n   1371 \n   1372             maybe_callable = com._apply_if_callable(key, self.obj)\n-> 1373             return self._getitem_axis(maybe_callable, axis=axis)\n        self._getitem_axis = <bound method _iLocIndexer._getitem_axis of <pandas.core.indexing._iLocIndexer object>>\n        maybe_callable = array([   0,    1,    2, ..., 5564, 5565, 5566])\n        axis = 0\n   1374 \n   1375     def _is_scalar_access(self, key):\n   1376         raise NotImplementedError()\n   1377 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self=<pandas.core.indexing._iLocIndexer object>, key=array([   0,    1,    2, ..., 5564, 5565, 5566]), axis=0)\n   1814             self._has_valid_type(key, axis)\n   1815             return self._getbool_axis(key, axis=axis)\n   1816 \n   1817         # a list of integers\n   1818         elif is_list_like_indexer(key):\n-> 1819             return self._get_list_axis(key, axis=axis)\n        self._get_list_axis = <bound method _iLocIndexer._get_list_axis of <pandas.core.indexing._iLocIndexer object>>\n        key = array([   0,    1,    2, ..., 5564, 5565, 5566])\n        axis = 0\n   1820 \n   1821         # a single integer\n   1822         else:\n   1823             key = self._convert_scalar_indexer(key, axis)\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in _get_list_axis(self=<pandas.core.indexing._iLocIndexer object>, key=array([   0,    1,    2, ..., 5564, 5565, 5566]), axis=0)\n   1789         Series object\n   1790         \"\"\"\n   1791         if axis is None:\n   1792             axis = self.axis or 0\n   1793         try:\n-> 1794             return self.obj._take(key, axis=axis, convert=False)\n        self.obj._take = <bound method NDFrame._take of       body_len  p...000000   0.0   0.0  \n\n[5567 rows x 8106 columns]>\n        key = array([   0,    1,    2, ..., 5564, 5565, 5566])\n        axis = 0\n   1795         except IndexError:\n   1796             # re-raise with different error message\n   1797             raise IndexError(\"positional indexers are out-of-bounds\")\n   1798 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in _take(self=      body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], indices=array([   0,    1,    2, ..., 5564, 5565, 5566]), axis=0, convert=False, is_copy=True)\n   2138         numpy.take\n   2139         \"\"\"\n   2140 \n   2141     @Appender(_shared_docs['_take'])\n   2142     def _take(self, indices, axis=0, convert=True, is_copy=True):\n-> 2143         self._consolidate_inplace()\n        self._consolidate_inplace = <bound method NDFrame._consolidate_inplace of   ...000000   0.0   0.0  \n\n[5567 rows x 8106 columns]>\n   2144 \n   2145         if convert:\n   2146             indices = maybe_convert_indices(indices, len(self._get_axis(axis)))\n   2147 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in _consolidate_inplace(self=      body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns])\n   3672         \"\"\"Consolidate data in place and return None\"\"\"\n   3673 \n   3674         def f():\n   3675             self._data = self._data.consolidate()\n   3676 \n-> 3677         self._protect_consolidate(f)\n        self._protect_consolidate = <bound method NDFrame._protect_consolidate of   ...000000   0.0   0.0  \n\n[5567 rows x 8106 columns]>\n        f = <function NDFrame._consolidate_inplace.<locals>.f>\n   3678 \n   3679     def _consolidate(self, inplace=False):\n   3680         \"\"\"\n   3681         Compute NDFrame with \"consolidated\" internals (data of each dtype\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in _protect_consolidate(self=      body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], f=<function NDFrame._consolidate_inplace.<locals>.f>)\n   3661     def _protect_consolidate(self, f):\n   3662         \"\"\"Consolidate _data -- if the blocks have changed, then clear the\n   3663         cache\n   3664         \"\"\"\n   3665         blocks_before = len(self._data.blocks)\n-> 3666         result = f()\n        result = undefined\n        f = <function NDFrame._consolidate_inplace.<locals>.f>\n   3667         if len(self._data.blocks) != blocks_before:\n   3668             self._clear_item_cache()\n   3669         return result\n   3670 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in f()\n   3670 \n   3671     def _consolidate_inplace(self):\n   3672         \"\"\"Consolidate data in place and return None\"\"\"\n   3673 \n   3674         def f():\n-> 3675             self._data = self._data.consolidate()\n   3676 \n   3677         self._protect_consolidate(f)\n   3678 \n   3679     def _consolidate(self, inplace=False):\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py in consolidate(self=BlockManager\nItems: Index(['body_len',   'punct%...k: slice(2, 8106, 1), 8104 x 5567, dtype: float64)\n   3821         if self.is_consolidated():\n   3822             return self\n   3823 \n   3824         bm = self.__class__(self.blocks, self.axes)\n   3825         bm._is_consolidated = False\n-> 3826         bm._consolidate_inplace()\n        bm._consolidate_inplace = <bound method BlockManager._consolidate_inplace ...: slice(2, 8106, 1), 8104 x 5567, dtype: float64>\n   3827         return bm\n   3828 \n   3829     def _consolidate_inplace(self):\n   3830         if not self.is_consolidated():\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py in _consolidate_inplace(self=BlockManager\nItems: Index(['body_len',   'punct%...k: slice(2, 8106, 1), 8104 x 5567, dtype: float64)\n   3826         bm._consolidate_inplace()\n   3827         return bm\n   3828 \n   3829     def _consolidate_inplace(self):\n   3830         if not self.is_consolidated():\n-> 3831             self.blocks = tuple(_consolidate(self.blocks))\n        self.blocks = (IntBlock: slice(0, 1, 1), 1 x 5567, dtype: int64, FloatBlock: slice(1, 2, 1), 1 x 5567, dtype: float64, FloatBlock: slice(2, 8106, 1), 8104 x 5567, dtype: float64)\n   3832             self._is_consolidated = True\n   3833             self._known_consolidated = True\n   3834             self._rebuild_blknos_and_blklocs()\n   3835 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py in _consolidate(blocks=(IntBlock: slice(0, 1, 1), 1 x 5567, dtype: int64, FloatBlock: slice(1, 2, 1), 1 x 5567, dtype: float64, FloatBlock: slice(2, 8106, 1), 8104 x 5567, dtype: float64))\n   4848     grouper = itertools.groupby(sorted(blocks, key=gkey), gkey)\n   4849 \n   4850     new_blocks = []\n   4851     for (_can_consolidate, dtype), group_blocks in grouper:\n   4852         merged_blocks = _merge_blocks(list(group_blocks), dtype=dtype,\n-> 4853                                       _can_consolidate=_can_consolidate)\n        _can_consolidate = True\n   4854         new_blocks = _extend_blocks(merged_blocks, new_blocks)\n   4855     return new_blocks\n   4856 \n   4857 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py in _merge_blocks(blocks=[FloatBlock: slice(1, 2, 1), 1 x 5567, dtype: float64, FloatBlock: slice(2, 8106, 1), 8104 x 5567, dtype: float64], dtype='float64', _can_consolidate=True)\n   4871         # combination of those slices is a slice, too.\n   4872         new_mgr_locs = np.concatenate([b.mgr_locs.as_array for b in blocks])\n   4873         new_values = _vstack([b.values for b in blocks], dtype)\n   4874 \n   4875         argsort = np.argsort(new_mgr_locs)\n-> 4876         new_values = new_values[argsort]\n        new_values = array([[  4.7,   4.1,   3.2, ...,  14.6,   1. , ...[  0. ,   0. ,   0. , ...,   0. ,   0. ,   0. ]])\n        argsort = array([   0,    1,    2, ..., 8102, 8103, 8104])\n   4877         new_mgr_locs = new_mgr_locs[argsort]\n   4878 \n   4879         return make_block(new_values, fastpath=True, placement=new_mgr_locs)\n   4880 \n\nMemoryError: \n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 427, in _fit_and_score\n    X_train, y_train = _safe_split(estimator, X, y, train)\n  File \"/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\", line 200, in _safe_split\n    X_subset = safe_indexing(X, indices)\n  File \"/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py\", line 149, in safe_indexing\n    return X.iloc[indices]\n  File \"/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1373, in __getitem__\n    return self._getitem_axis(maybe_callable, axis=axis)\n  File \"/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1819, in _getitem_axis\n    return self._get_list_axis(key, axis=axis)\n  File \"/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1794, in _get_list_axis\n    return self.obj._take(key, axis=axis, convert=False)\n  File \"/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 2143, in _take\n    self._consolidate_inplace()\n  File \"/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 3677, in _consolidate_inplace\n    self._protect_consolidate(f)\n  File \"/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 3666, in _protect_consolidate\n    result = f()\n  File \"/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 3675, in f\n    self._data = self._data.consolidate()\n  File \"/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 3826, in consolidate\n    bm._consolidate_inplace()\n  File \"/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 3831, in _consolidate_inplace\n    self.blocks = tuple(_consolidate(self.blocks))\n  File \"/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 4853, in _consolidate\n    _can_consolidate=_can_consolidate)\n  File \"/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 4876, in _merge_blocks\n    new_values = new_values[argsort]\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/bmacs/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nMemoryError                                        Mon May 28 14:38:33 2018\nPID: 10579                   Python 3.6.4: /home/bmacs/anaconda3/bin/python\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False),       body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], 0       spam\n1        ham\n2        ham\n3        ...     ham\nName: label, Length: 5567, dtype: object, {'score': make_scorer(accuracy_score)}, array([   0,    1,    2, ..., 5564, 5565, 5566]), array([2228, 2229, 2230, ..., 3338, 3339, 3340]), 0, None, None), {'return_times': True, 'return_train_score': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False),       body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], 0       spam\n1        ham\n2        ham\n3        ...     ham\nName: label, Length: 5567, dtype: object, {'score': make_scorer(accuracy_score)}, array([   0,    1,    2, ..., 5564, 5565, 5566]), array([2228, 2229, 2230, ..., 3338, 3339, 3340]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=      body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], y=0       spam\n1        ham\n2        ham\n3        ...     ham\nName: label, Length: 5567, dtype: object, scorer={'score': make_scorer(accuracy_score)}, train=array([   0,    1,    2, ..., 5564, 5565, 5566]), test=array([2228, 2229, 2230, ..., 3338, 3339, 3340]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    422     if parameters is not None:\n    423         estimator.set_params(**parameters)\n    424 \n    425     start_time = time.time()\n    426 \n--> 427     X_train, y_train = _safe_split(estimator, X, y, train)\n        X_train = undefined\n        y_train = undefined\n        estimator = RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False)\n        X =       body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns]\n        y = 0       spam\n1        ham\n2        ham\n3        ...     ham\nName: label, Length: 5567, dtype: object\n        train = array([   0,    1,    2, ..., 5564, 5565, 5566])\n    428     X_test, y_test = _safe_split(estimator, X, y, test, train)\n    429 \n    430     is_multimetric = not callable(scorer)\n    431     n_scorers = len(scorer.keys()) if is_multimetric else 1\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _safe_split(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=      body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], y=0       spam\n1        ham\n2        ham\n3        ...     ham\nName: label, Length: 5567, dtype: object, indices=array([   0,    1,    2, ..., 5564, 5565, 5566]), train_indices=None)\n    195         if train_indices is None:\n    196             X_subset = X[np.ix_(indices, indices)]\n    197         else:\n    198             X_subset = X[np.ix_(indices, train_indices)]\n    199     else:\n--> 200         X_subset = safe_indexing(X, indices)\n        X_subset = undefined\n        X =       body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns]\n        indices = array([   0,    1,    2, ..., 5564, 5565, 5566])\n    201 \n    202     if y is not None:\n    203         y_subset = safe_indexing(y, indices)\n    204     else:\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py in safe_indexing(X=      body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], indices=array([   0,    1,    2, ..., 5564, 5565, 5566]))\n    144     if hasattr(X, \"iloc\"):\n    145         # Work-around for indexing with read-only indices in pandas\n    146         indices = indices if indices.flags.writeable else indices.copy()\n    147         # Pandas Dataframes and Series\n    148         try:\n--> 149             return X.iloc[indices]\n        X.iloc = <pandas.core.indexing._iLocIndexer object>\n        indices = array([   0,    1,    2, ..., 5564, 5565, 5566])\n    150         except ValueError:\n    151             # Cython typed memoryviews internally used in pandas do not support\n    152             # readonly buffers.\n    153             warnings.warn(\"Copying input dataframe for slicing.\",\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self=<pandas.core.indexing._iLocIndexer object>, key=array([   0,    1,    2, ..., 5564, 5565, 5566]))\n   1368         else:\n   1369             # we by definition only have the 0th axis\n   1370             axis = self.axis or 0\n   1371 \n   1372             maybe_callable = com._apply_if_callable(key, self.obj)\n-> 1373             return self._getitem_axis(maybe_callable, axis=axis)\n        self._getitem_axis = <bound method _iLocIndexer._getitem_axis of <pandas.core.indexing._iLocIndexer object>>\n        maybe_callable = array([   0,    1,    2, ..., 5564, 5565, 5566])\n        axis = 0\n   1374 \n   1375     def _is_scalar_access(self, key):\n   1376         raise NotImplementedError()\n   1377 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self=<pandas.core.indexing._iLocIndexer object>, key=array([   0,    1,    2, ..., 5564, 5565, 5566]), axis=0)\n   1814             self._has_valid_type(key, axis)\n   1815             return self._getbool_axis(key, axis=axis)\n   1816 \n   1817         # a list of integers\n   1818         elif is_list_like_indexer(key):\n-> 1819             return self._get_list_axis(key, axis=axis)\n        self._get_list_axis = <bound method _iLocIndexer._get_list_axis of <pandas.core.indexing._iLocIndexer object>>\n        key = array([   0,    1,    2, ..., 5564, 5565, 5566])\n        axis = 0\n   1820 \n   1821         # a single integer\n   1822         else:\n   1823             key = self._convert_scalar_indexer(key, axis)\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in _get_list_axis(self=<pandas.core.indexing._iLocIndexer object>, key=array([   0,    1,    2, ..., 5564, 5565, 5566]), axis=0)\n   1789         Series object\n   1790         \"\"\"\n   1791         if axis is None:\n   1792             axis = self.axis or 0\n   1793         try:\n-> 1794             return self.obj._take(key, axis=axis, convert=False)\n        self.obj._take = <bound method NDFrame._take of       body_len  p...000000   0.0   0.0  \n\n[5567 rows x 8106 columns]>\n        key = array([   0,    1,    2, ..., 5564, 5565, 5566])\n        axis = 0\n   1795         except IndexError:\n   1796             # re-raise with different error message\n   1797             raise IndexError(\"positional indexers are out-of-bounds\")\n   1798 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in _take(self=      body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], indices=array([   0,    1,    2, ..., 5564, 5565, 5566]), axis=0, convert=False, is_copy=True)\n   2138         numpy.take\n   2139         \"\"\"\n   2140 \n   2141     @Appender(_shared_docs['_take'])\n   2142     def _take(self, indices, axis=0, convert=True, is_copy=True):\n-> 2143         self._consolidate_inplace()\n        self._consolidate_inplace = <bound method NDFrame._consolidate_inplace of   ...000000   0.0   0.0  \n\n[5567 rows x 8106 columns]>\n   2144 \n   2145         if convert:\n   2146             indices = maybe_convert_indices(indices, len(self._get_axis(axis)))\n   2147 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in _consolidate_inplace(self=      body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns])\n   3672         \"\"\"Consolidate data in place and return None\"\"\"\n   3673 \n   3674         def f():\n   3675             self._data = self._data.consolidate()\n   3676 \n-> 3677         self._protect_consolidate(f)\n        self._protect_consolidate = <bound method NDFrame._protect_consolidate of   ...000000   0.0   0.0  \n\n[5567 rows x 8106 columns]>\n        f = <function NDFrame._consolidate_inplace.<locals>.f>\n   3678 \n   3679     def _consolidate(self, inplace=False):\n   3680         \"\"\"\n   3681         Compute NDFrame with \"consolidated\" internals (data of each dtype\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in _protect_consolidate(self=      body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], f=<function NDFrame._consolidate_inplace.<locals>.f>)\n   3661     def _protect_consolidate(self, f):\n   3662         \"\"\"Consolidate _data -- if the blocks have changed, then clear the\n   3663         cache\n   3664         \"\"\"\n   3665         blocks_before = len(self._data.blocks)\n-> 3666         result = f()\n        result = undefined\n        f = <function NDFrame._consolidate_inplace.<locals>.f>\n   3667         if len(self._data.blocks) != blocks_before:\n   3668             self._clear_item_cache()\n   3669         return result\n   3670 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in f()\n   3670 \n   3671     def _consolidate_inplace(self):\n   3672         \"\"\"Consolidate data in place and return None\"\"\"\n   3673 \n   3674         def f():\n-> 3675             self._data = self._data.consolidate()\n   3676 \n   3677         self._protect_consolidate(f)\n   3678 \n   3679     def _consolidate(self, inplace=False):\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py in consolidate(self=BlockManager\nItems: Index(['body_len',   'punct%...k: slice(2, 8106, 1), 8104 x 5567, dtype: float64)\n   3821         if self.is_consolidated():\n   3822             return self\n   3823 \n   3824         bm = self.__class__(self.blocks, self.axes)\n   3825         bm._is_consolidated = False\n-> 3826         bm._consolidate_inplace()\n        bm._consolidate_inplace = <bound method BlockManager._consolidate_inplace ...: slice(2, 8106, 1), 8104 x 5567, dtype: float64>\n   3827         return bm\n   3828 \n   3829     def _consolidate_inplace(self):\n   3830         if not self.is_consolidated():\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py in _consolidate_inplace(self=BlockManager\nItems: Index(['body_len',   'punct%...k: slice(2, 8106, 1), 8104 x 5567, dtype: float64)\n   3826         bm._consolidate_inplace()\n   3827         return bm\n   3828 \n   3829     def _consolidate_inplace(self):\n   3830         if not self.is_consolidated():\n-> 3831             self.blocks = tuple(_consolidate(self.blocks))\n        self.blocks = (IntBlock: slice(0, 1, 1), 1 x 5567, dtype: int64, FloatBlock: slice(1, 2, 1), 1 x 5567, dtype: float64, FloatBlock: slice(2, 8106, 1), 8104 x 5567, dtype: float64)\n   3832             self._is_consolidated = True\n   3833             self._known_consolidated = True\n   3834             self._rebuild_blknos_and_blklocs()\n   3835 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py in _consolidate(blocks=(IntBlock: slice(0, 1, 1), 1 x 5567, dtype: int64, FloatBlock: slice(1, 2, 1), 1 x 5567, dtype: float64, FloatBlock: slice(2, 8106, 1), 8104 x 5567, dtype: float64))\n   4848     grouper = itertools.groupby(sorted(blocks, key=gkey), gkey)\n   4849 \n   4850     new_blocks = []\n   4851     for (_can_consolidate, dtype), group_blocks in grouper:\n   4852         merged_blocks = _merge_blocks(list(group_blocks), dtype=dtype,\n-> 4853                                       _can_consolidate=_can_consolidate)\n        _can_consolidate = True\n   4854         new_blocks = _extend_blocks(merged_blocks, new_blocks)\n   4855     return new_blocks\n   4856 \n   4857 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py in _merge_blocks(blocks=[FloatBlock: slice(1, 2, 1), 1 x 5567, dtype: float64, FloatBlock: slice(2, 8106, 1), 8104 x 5567, dtype: float64], dtype='float64', _can_consolidate=True)\n   4871         # combination of those slices is a slice, too.\n   4872         new_mgr_locs = np.concatenate([b.mgr_locs.as_array for b in blocks])\n   4873         new_values = _vstack([b.values for b in blocks], dtype)\n   4874 \n   4875         argsort = np.argsort(new_mgr_locs)\n-> 4876         new_values = new_values[argsort]\n        new_values = array([[  4.7,   4.1,   3.2, ...,  14.6,   1. , ...[  0. ,   0. ,   0. , ...,   0. ,   0. ,   0. ]])\n        argsort = array([   0,    1,    2, ..., 8102, 8103, 8104])\n   4877         new_mgr_locs = new_mgr_locs[argsort]\n   4878 \n   4879         return make_block(new_values, fastpath=True, placement=new_mgr_locs)\n   4880 \n\nMemoryError: \n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nMemoryError                                        Mon May 28 14:38:33 2018\nPID: 10579                   Python 3.6.4: /home/bmacs/anaconda3/bin/python\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False),       body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], 0       spam\n1        ham\n2        ham\n3        ...     ham\nName: label, Length: 5567, dtype: object, {'score': make_scorer(accuracy_score)}, array([   0,    1,    2, ..., 5564, 5565, 5566]), array([2228, 2229, 2230, ..., 3338, 3339, 3340]), 0, None, None), {'return_times': True, 'return_train_score': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False),       body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], 0       spam\n1        ham\n2        ham\n3        ...     ham\nName: label, Length: 5567, dtype: object, {'score': make_scorer(accuracy_score)}, array([   0,    1,    2, ..., 5564, 5565, 5566]), array([2228, 2229, 2230, ..., 3338, 3339, 3340]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=      body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], y=0       spam\n1        ham\n2        ham\n3        ...     ham\nName: label, Length: 5567, dtype: object, scorer={'score': make_scorer(accuracy_score)}, train=array([   0,    1,    2, ..., 5564, 5565, 5566]), test=array([2228, 2229, 2230, ..., 3338, 3339, 3340]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    422     if parameters is not None:\n    423         estimator.set_params(**parameters)\n    424 \n    425     start_time = time.time()\n    426 \n--> 427     X_train, y_train = _safe_split(estimator, X, y, train)\n        X_train = undefined\n        y_train = undefined\n        estimator = RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False)\n        X =       body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns]\n        y = 0       spam\n1        ham\n2        ham\n3        ...     ham\nName: label, Length: 5567, dtype: object\n        train = array([   0,    1,    2, ..., 5564, 5565, 5566])\n    428     X_test, y_test = _safe_split(estimator, X, y, test, train)\n    429 \n    430     is_multimetric = not callable(scorer)\n    431     n_scorers = len(scorer.keys()) if is_multimetric else 1\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _safe_split(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=      body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], y=0       spam\n1        ham\n2        ham\n3        ...     ham\nName: label, Length: 5567, dtype: object, indices=array([   0,    1,    2, ..., 5564, 5565, 5566]), train_indices=None)\n    195         if train_indices is None:\n    196             X_subset = X[np.ix_(indices, indices)]\n    197         else:\n    198             X_subset = X[np.ix_(indices, train_indices)]\n    199     else:\n--> 200         X_subset = safe_indexing(X, indices)\n        X_subset = undefined\n        X =       body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns]\n        indices = array([   0,    1,    2, ..., 5564, 5565, 5566])\n    201 \n    202     if y is not None:\n    203         y_subset = safe_indexing(y, indices)\n    204     else:\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py in safe_indexing(X=      body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], indices=array([   0,    1,    2, ..., 5564, 5565, 5566]))\n    144     if hasattr(X, \"iloc\"):\n    145         # Work-around for indexing with read-only indices in pandas\n    146         indices = indices if indices.flags.writeable else indices.copy()\n    147         # Pandas Dataframes and Series\n    148         try:\n--> 149             return X.iloc[indices]\n        X.iloc = <pandas.core.indexing._iLocIndexer object>\n        indices = array([   0,    1,    2, ..., 5564, 5565, 5566])\n    150         except ValueError:\n    151             # Cython typed memoryviews internally used in pandas do not support\n    152             # readonly buffers.\n    153             warnings.warn(\"Copying input dataframe for slicing.\",\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self=<pandas.core.indexing._iLocIndexer object>, key=array([   0,    1,    2, ..., 5564, 5565, 5566]))\n   1368         else:\n   1369             # we by definition only have the 0th axis\n   1370             axis = self.axis or 0\n   1371 \n   1372             maybe_callable = com._apply_if_callable(key, self.obj)\n-> 1373             return self._getitem_axis(maybe_callable, axis=axis)\n        self._getitem_axis = <bound method _iLocIndexer._getitem_axis of <pandas.core.indexing._iLocIndexer object>>\n        maybe_callable = array([   0,    1,    2, ..., 5564, 5565, 5566])\n        axis = 0\n   1374 \n   1375     def _is_scalar_access(self, key):\n   1376         raise NotImplementedError()\n   1377 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self=<pandas.core.indexing._iLocIndexer object>, key=array([   0,    1,    2, ..., 5564, 5565, 5566]), axis=0)\n   1814             self._has_valid_type(key, axis)\n   1815             return self._getbool_axis(key, axis=axis)\n   1816 \n   1817         # a list of integers\n   1818         elif is_list_like_indexer(key):\n-> 1819             return self._get_list_axis(key, axis=axis)\n        self._get_list_axis = <bound method _iLocIndexer._get_list_axis of <pandas.core.indexing._iLocIndexer object>>\n        key = array([   0,    1,    2, ..., 5564, 5565, 5566])\n        axis = 0\n   1820 \n   1821         # a single integer\n   1822         else:\n   1823             key = self._convert_scalar_indexer(key, axis)\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in _get_list_axis(self=<pandas.core.indexing._iLocIndexer object>, key=array([   0,    1,    2, ..., 5564, 5565, 5566]), axis=0)\n   1789         Series object\n   1790         \"\"\"\n   1791         if axis is None:\n   1792             axis = self.axis or 0\n   1793         try:\n-> 1794             return self.obj._take(key, axis=axis, convert=False)\n        self.obj._take = <bound method NDFrame._take of       body_len  p...000000   0.0   0.0  \n\n[5567 rows x 8106 columns]>\n        key = array([   0,    1,    2, ..., 5564, 5565, 5566])\n        axis = 0\n   1795         except IndexError:\n   1796             # re-raise with different error message\n   1797             raise IndexError(\"positional indexers are out-of-bounds\")\n   1798 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in _take(self=      body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], indices=array([   0,    1,    2, ..., 5564, 5565, 5566]), axis=0, convert=False, is_copy=True)\n   2138         numpy.take\n   2139         \"\"\"\n   2140 \n   2141     @Appender(_shared_docs['_take'])\n   2142     def _take(self, indices, axis=0, convert=True, is_copy=True):\n-> 2143         self._consolidate_inplace()\n        self._consolidate_inplace = <bound method NDFrame._consolidate_inplace of   ...000000   0.0   0.0  \n\n[5567 rows x 8106 columns]>\n   2144 \n   2145         if convert:\n   2146             indices = maybe_convert_indices(indices, len(self._get_axis(axis)))\n   2147 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in _consolidate_inplace(self=      body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns])\n   3672         \"\"\"Consolidate data in place and return None\"\"\"\n   3673 \n   3674         def f():\n   3675             self._data = self._data.consolidate()\n   3676 \n-> 3677         self._protect_consolidate(f)\n        self._protect_consolidate = <bound method NDFrame._protect_consolidate of   ...000000   0.0   0.0  \n\n[5567 rows x 8106 columns]>\n        f = <function NDFrame._consolidate_inplace.<locals>.f>\n   3678 \n   3679     def _consolidate(self, inplace=False):\n   3680         \"\"\"\n   3681         Compute NDFrame with \"consolidated\" internals (data of each dtype\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in _protect_consolidate(self=      body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], f=<function NDFrame._consolidate_inplace.<locals>.f>)\n   3661     def _protect_consolidate(self, f):\n   3662         \"\"\"Consolidate _data -- if the blocks have changed, then clear the\n   3663         cache\n   3664         \"\"\"\n   3665         blocks_before = len(self._data.blocks)\n-> 3666         result = f()\n        result = undefined\n        f = <function NDFrame._consolidate_inplace.<locals>.f>\n   3667         if len(self._data.blocks) != blocks_before:\n   3668             self._clear_item_cache()\n   3669         return result\n   3670 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in f()\n   3670 \n   3671     def _consolidate_inplace(self):\n   3672         \"\"\"Consolidate data in place and return None\"\"\"\n   3673 \n   3674         def f():\n-> 3675             self._data = self._data.consolidate()\n   3676 \n   3677         self._protect_consolidate(f)\n   3678 \n   3679     def _consolidate(self, inplace=False):\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py in consolidate(self=BlockManager\nItems: Index(['body_len',   'punct%...k: slice(2, 8106, 1), 8104 x 5567, dtype: float64)\n   3821         if self.is_consolidated():\n   3822             return self\n   3823 \n   3824         bm = self.__class__(self.blocks, self.axes)\n   3825         bm._is_consolidated = False\n-> 3826         bm._consolidate_inplace()\n        bm._consolidate_inplace = <bound method BlockManager._consolidate_inplace ...: slice(2, 8106, 1), 8104 x 5567, dtype: float64>\n   3827         return bm\n   3828 \n   3829     def _consolidate_inplace(self):\n   3830         if not self.is_consolidated():\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py in _consolidate_inplace(self=BlockManager\nItems: Index(['body_len',   'punct%...k: slice(2, 8106, 1), 8104 x 5567, dtype: float64)\n   3826         bm._consolidate_inplace()\n   3827         return bm\n   3828 \n   3829     def _consolidate_inplace(self):\n   3830         if not self.is_consolidated():\n-> 3831             self.blocks = tuple(_consolidate(self.blocks))\n        self.blocks = (IntBlock: slice(0, 1, 1), 1 x 5567, dtype: int64, FloatBlock: slice(1, 2, 1), 1 x 5567, dtype: float64, FloatBlock: slice(2, 8106, 1), 8104 x 5567, dtype: float64)\n   3832             self._is_consolidated = True\n   3833             self._known_consolidated = True\n   3834             self._rebuild_blknos_and_blklocs()\n   3835 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py in _consolidate(blocks=(IntBlock: slice(0, 1, 1), 1 x 5567, dtype: int64, FloatBlock: slice(1, 2, 1), 1 x 5567, dtype: float64, FloatBlock: slice(2, 8106, 1), 8104 x 5567, dtype: float64))\n   4848     grouper = itertools.groupby(sorted(blocks, key=gkey), gkey)\n   4849 \n   4850     new_blocks = []\n   4851     for (_can_consolidate, dtype), group_blocks in grouper:\n   4852         merged_blocks = _merge_blocks(list(group_blocks), dtype=dtype,\n-> 4853                                       _can_consolidate=_can_consolidate)\n        _can_consolidate = True\n   4854         new_blocks = _extend_blocks(merged_blocks, new_blocks)\n   4855     return new_blocks\n   4856 \n   4857 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py in _merge_blocks(blocks=[FloatBlock: slice(1, 2, 1), 1 x 5567, dtype: float64, FloatBlock: slice(2, 8106, 1), 8104 x 5567, dtype: float64], dtype='float64', _can_consolidate=True)\n   4871         # combination of those slices is a slice, too.\n   4872         new_mgr_locs = np.concatenate([b.mgr_locs.as_array for b in blocks])\n   4873         new_values = _vstack([b.values for b in blocks], dtype)\n   4874 \n   4875         argsort = np.argsort(new_mgr_locs)\n-> 4876         new_values = new_values[argsort]\n        new_values = array([[  4.7,   4.1,   3.2, ...,  14.6,   1. , ...[  0. ,   0. ,   0. , ...,   0. ,   0. ,   0. ]])\n        argsort = array([   0,    1,    2, ..., 8102, 8103, 8104])\n   4877         new_mgr_locs = new_mgr_locs[argsort]\n   4878 \n   4879         return make_block(new_values, fastpath=True, placement=new_mgr_locs)\n   4880 \n\nMemoryError: \n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibMemoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-c17948fdf9b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    319\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[1;32m    322\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             return_times=True)\n\u001b[0;32m--> 195\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibMemoryError\u001b[0m: JoblibMemoryError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7f038491f5d0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/bmacs/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/bmacs/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/bmacs/.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f038491f5d0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/bmacs/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/bmacs/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/bmacs/.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         self.io_loop = ioloop.IOLoop.current()\n    477         try:\n--> 478             self.io_loop.start()\n        self.io_loop.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    479         except KeyboardInterrupt:\n    480             pass\n    481 \n    482 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"cross_val_score(rf, X_features, data['label'], cv=k_fold, scoring='accuracy', n_jobs=-1)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 5, 28, 18, 38, 30, 38732, tzinfo=tzutc()), 'msg_id': '9de4633913f240698a935f06d57ef25b', 'msg_type': 'execute_request', 'session': 'c493ad538f5f4b308ca3a30afff2e601', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '9de4633913f240698a935f06d57ef25b', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'c493ad538f5f4b308ca3a30afff2e601']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"cross_val_score(rf, X_features, data['label'], cv=k_fold, scoring='accuracy', n_jobs=-1)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 5, 28, 18, 38, 30, 38732, tzinfo=tzutc()), 'msg_id': '9de4633913f240698a935f06d57ef25b', 'msg_type': 'execute_request', 'session': 'c493ad538f5f4b308ca3a30afff2e601', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '9de4633913f240698a935f06d57ef25b', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'c493ad538f5f4b308ca3a30afff2e601'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"cross_val_score(rf, X_features, data['label'], cv=k_fold, scoring='accuracy', n_jobs=-1)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 5, 28, 18, 38, 30, 38732, tzinfo=tzutc()), 'msg_id': '9de4633913f240698a935f06d57ef25b', 'msg_type': 'execute_request', 'session': 'c493ad538f5f4b308ca3a30afff2e601', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '9de4633913f240698a935f06d57ef25b', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"cross_val_score(rf, X_features, data['label'], cv=k_fold, scoring='accuracy', n_jobs=-1)\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"cross_val_score(rf, X_features, data['label'], cv=k_fold, scoring='accuracy', n_jobs=-1)\"\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"cross_val_score(rf, X_features, data['label'], cv=k_fold, scoring='accuracy', n_jobs=-1)\",), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"cross_val_score(rf, X_features, data['label'], cv=k_fold, scoring='accuracy', n_jobs=-1)\",)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"cross_val_score(rf, X_features, data['label'], cv=k_fold, scoring='accuracy', n_jobs=-1)\", store_history=True, silent=False, shell_futures=True)\n   2723                 self.displayhook.exec_result = result\n   2724 \n   2725                 # Execute the user code\n   2726                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2727                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2728                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2729                 \n   2730                 self.last_execution_succeeded = not has_raised\n   2731                 self.last_execution_result = result\n   2732 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name='<ipython-input-22-c17948fdf9b6>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f034248ee10, executi..._before_exec=None error_in_exec=None result=None>)\n   2851                     return True\n   2852 \n   2853             for i, node in enumerate(to_run_interactive):\n   2854                 mod = ast.Interactive([node])\n   2855                 code = compiler(mod, cell_name, \"single\")\n-> 2856                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f0341fba6f0, file \"<ipython-input-22-c17948fdf9b6>\", line 1>\n        result = <ExecutionResult object at 7f034248ee10, executi..._before_exec=None error_in_exec=None result=None>\n   2857                     return True\n   2858 \n   2859             # Flush softspace\n   2860             if softspace(sys.stdout, 0):\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f0341fba6f0, file \"<ipython-input-22-c17948fdf9b6>\", line 1>, result=<ExecutionResult object at 7f034248ee10, executi..._before_exec=None error_in_exec=None result=None>)\n   2905         outflag = True  # happens in more places, so it's easier as default\n   2906         try:\n   2907             try:\n   2908                 self.hooks.pre_run_code_hook()\n   2909                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2910                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f0341fba6f0, file \"<ipython-input-22-c17948fdf9b6>\", line 1>\n        self.user_global_ns = {'In': ['', 'import nltk\\nimport pandas as pd\\nimport re\\nfrom s...raction.text import TfidfVectorizer\\nimport string', \"stopwords = nltk.corpus.stopwords.words('english')\\nps = nltk.PorterStemmer()\", 'data = pd.read_csv(\"SMSSpamCollection.tsv\", sep=\\'\\\\t\\')\\ndata.columns = [\\'label\\', \\'body_text\\']', 'def count_punct(text):\\n    count = sum([1 for ch...round(count/(len(text) - text.count(\" \")), 3)*100', \"data['body_len'] = data['body_text'].apply(lambd...ata['body_text'].apply(lambda x: count_punct((x))\", \"data['body_len'] = data['body_text'].apply(lambd...data['body_text'].apply(lambda x: count_punct(x))\", 'def clean_text(text):\\n    text = \"\".join([word.l... tokens if word not in stopwords]\\n    return text', \"tfidf_vect = TfidfVectorizer(analyzer=clean_text...idf = tfidf_vect.fit_transform(data['body_text'])\", \"X_features = pd.concat([data['body_len'], data['...me(X_tfidf.toarray())], axis=1)\\nX_features.head()\", 'from sklearn.ensemble import RandomForestClassifier', 'print(dir(RandomForestClassifier))\\nprint(RandomForestClassifier())', 'from sklearn.model_selection import KFold, cross_val_score', 'rf = RandomForestClassifier(n_jobs=-1)', 'k_fold = KFold(n_splits=5)', \"cross_val_score(rf, X_features, data['label'], cv=k_fold, scoring='accuracy', n_jobs=-1)\", 'k_fold = KFold(n_splits=5)', \"cross_val_score(rf, X_features, data['label'], cv=k_fold, scoring='accuracy', n_jobs=-1)\", 'from sklearn.model_selection import KFold, cross_val_score', 'rf = RandomForestClassifier(n_jobs=-1)', ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'Out': {9:    body_len  punct%    0    1    2    3    4    ... 0.0   0.0   0.0   0.0  \n\n[5 rows x 8106 columns]}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'TfidfVectorizer': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, 'X_features':       body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], 'X_tfidf': <5567x8104 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, '_':    body_len  punct%    0    1    2    3    4    ... 0.0   0.0   0.0   0.0  \n\n[5 rows x 8106 columns], '_9':    body_len  punct%    0    1    2    3    4    ... 0.0   0.0   0.0   0.0  \n\n[5 rows x 8106 columns], '__': '', ...}\n        self.user_ns = {'In': ['', 'import nltk\\nimport pandas as pd\\nimport re\\nfrom s...raction.text import TfidfVectorizer\\nimport string', \"stopwords = nltk.corpus.stopwords.words('english')\\nps = nltk.PorterStemmer()\", 'data = pd.read_csv(\"SMSSpamCollection.tsv\", sep=\\'\\\\t\\')\\ndata.columns = [\\'label\\', \\'body_text\\']', 'def count_punct(text):\\n    count = sum([1 for ch...round(count/(len(text) - text.count(\" \")), 3)*100', \"data['body_len'] = data['body_text'].apply(lambd...ata['body_text'].apply(lambda x: count_punct((x))\", \"data['body_len'] = data['body_text'].apply(lambd...data['body_text'].apply(lambda x: count_punct(x))\", 'def clean_text(text):\\n    text = \"\".join([word.l... tokens if word not in stopwords]\\n    return text', \"tfidf_vect = TfidfVectorizer(analyzer=clean_text...idf = tfidf_vect.fit_transform(data['body_text'])\", \"X_features = pd.concat([data['body_len'], data['...me(X_tfidf.toarray())], axis=1)\\nX_features.head()\", 'from sklearn.ensemble import RandomForestClassifier', 'print(dir(RandomForestClassifier))\\nprint(RandomForestClassifier())', 'from sklearn.model_selection import KFold, cross_val_score', 'rf = RandomForestClassifier(n_jobs=-1)', 'k_fold = KFold(n_splits=5)', \"cross_val_score(rf, X_features, data['label'], cv=k_fold, scoring='accuracy', n_jobs=-1)\", 'k_fold = KFold(n_splits=5)', \"cross_val_score(rf, X_features, data['label'], cv=k_fold, scoring='accuracy', n_jobs=-1)\", 'from sklearn.model_selection import KFold, cross_val_score', 'rf = RandomForestClassifier(n_jobs=-1)', ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'Out': {9:    body_len  punct%    0    1    2    3    4    ... 0.0   0.0   0.0   0.0  \n\n[5 rows x 8106 columns]}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'TfidfVectorizer': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, 'X_features':       body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], 'X_tfidf': <5567x8104 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, '_':    body_len  punct%    0    1    2    3    4    ... 0.0   0.0   0.0   0.0  \n\n[5 rows x 8106 columns], '_9':    body_len  punct%    0    1    2    3    4    ... 0.0   0.0   0.0   0.0  \n\n[5 rows x 8106 columns], '__': '', ...}\n   2911             finally:\n   2912                 # Reset our crash handler in place\n   2913                 sys.excepthook = old_excepthook\n   2914         except SystemExit as e:\n\n...........................................................................\n/home/bmacs/BigData/Week9/<ipython-input-22-c17948fdf9b6> in <module>()\n----> 1 cross_val_score(rf, X_features, data['label'], cv=k_fold, scoring='accuracy', n_jobs=-1)\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in cross_val_score(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=      body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], y=0       spam\n1        ham\n2        ham\n3        ...     ham\nName: label, Length: 5567, dtype: object, groups=None, scoring='accuracy', cv=KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')\n    316     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n    317                                 scoring={'score': scorer}, cv=cv,\n    318                                 return_train_score=False,\n    319                                 n_jobs=n_jobs, verbose=verbose,\n    320                                 fit_params=fit_params,\n--> 321                                 pre_dispatch=pre_dispatch)\n        pre_dispatch = '2*n_jobs'\n    322     return cv_results['test_score']\n    323 \n    324 \n    325 def _fit_and_score(estimator, X, y, scorer, train, test, verbose,\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=      body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], y=0       spam\n1        ham\n2        ham\n3        ...     ham\nName: label, Length: 5567, dtype: object, groups=None, scoring={'score': make_scorer(accuracy_score)}, cv=KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False)\n    190     scores = parallel(\n    191         delayed(_fit_and_score)(\n    192             clone(estimator), X, y, scorers, train, test, verbose, None,\n    193             fit_params, return_train_score=return_train_score,\n    194             return_times=True)\n--> 195         for train, test in cv.split(X, y, groups))\n        cv.split = <bound method _BaseKFold.split of KFold(n_splits=5, random_state=None, shuffle=False)>\n        X =       body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns]\n        y = 0       spam\n1        ham\n2        ham\n3        ...     ham\nName: label, Length: 5567, dtype: object\n        groups = None\n    196 \n    197     if return_train_score:\n    198         train_scores, test_scores, fit_times, score_times = zip(*scores)\n    199         train_scores = _aggregate_score_dicts(train_scores)\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object cross_validate.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nMemoryError                                        Mon May 28 14:38:33 2018\nPID: 10579                   Python 3.6.4: /home/bmacs/anaconda3/bin/python\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False),       body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], 0       spam\n1        ham\n2        ham\n3        ...     ham\nName: label, Length: 5567, dtype: object, {'score': make_scorer(accuracy_score)}, array([   0,    1,    2, ..., 5564, 5565, 5566]), array([2228, 2229, 2230, ..., 3338, 3339, 3340]), 0, None, None), {'return_times': True, 'return_train_score': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False),       body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], 0       spam\n1        ham\n2        ham\n3        ...     ham\nName: label, Length: 5567, dtype: object, {'score': make_scorer(accuracy_score)}, array([   0,    1,    2, ..., 5564, 5565, 5566]), array([2228, 2229, 2230, ..., 3338, 3339, 3340]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=      body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], y=0       spam\n1        ham\n2        ham\n3        ...     ham\nName: label, Length: 5567, dtype: object, scorer={'score': make_scorer(accuracy_score)}, train=array([   0,    1,    2, ..., 5564, 5565, 5566]), test=array([2228, 2229, 2230, ..., 3338, 3339, 3340]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    422     if parameters is not None:\n    423         estimator.set_params(**parameters)\n    424 \n    425     start_time = time.time()\n    426 \n--> 427     X_train, y_train = _safe_split(estimator, X, y, train)\n        X_train = undefined\n        y_train = undefined\n        estimator = RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False)\n        X =       body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns]\n        y = 0       spam\n1        ham\n2        ham\n3        ...     ham\nName: label, Length: 5567, dtype: object\n        train = array([   0,    1,    2, ..., 5564, 5565, 5566])\n    428     X_test, y_test = _safe_split(estimator, X, y, test, train)\n    429 \n    430     is_multimetric = not callable(scorer)\n    431     n_scorers = len(scorer.keys()) if is_multimetric else 1\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _safe_split(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=      body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], y=0       spam\n1        ham\n2        ham\n3        ...     ham\nName: label, Length: 5567, dtype: object, indices=array([   0,    1,    2, ..., 5564, 5565, 5566]), train_indices=None)\n    195         if train_indices is None:\n    196             X_subset = X[np.ix_(indices, indices)]\n    197         else:\n    198             X_subset = X[np.ix_(indices, train_indices)]\n    199     else:\n--> 200         X_subset = safe_indexing(X, indices)\n        X_subset = undefined\n        X =       body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns]\n        indices = array([   0,    1,    2, ..., 5564, 5565, 5566])\n    201 \n    202     if y is not None:\n    203         y_subset = safe_indexing(y, indices)\n    204     else:\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py in safe_indexing(X=      body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], indices=array([   0,    1,    2, ..., 5564, 5565, 5566]))\n    144     if hasattr(X, \"iloc\"):\n    145         # Work-around for indexing with read-only indices in pandas\n    146         indices = indices if indices.flags.writeable else indices.copy()\n    147         # Pandas Dataframes and Series\n    148         try:\n--> 149             return X.iloc[indices]\n        X.iloc = <pandas.core.indexing._iLocIndexer object>\n        indices = array([   0,    1,    2, ..., 5564, 5565, 5566])\n    150         except ValueError:\n    151             # Cython typed memoryviews internally used in pandas do not support\n    152             # readonly buffers.\n    153             warnings.warn(\"Copying input dataframe for slicing.\",\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self=<pandas.core.indexing._iLocIndexer object>, key=array([   0,    1,    2, ..., 5564, 5565, 5566]))\n   1368         else:\n   1369             # we by definition only have the 0th axis\n   1370             axis = self.axis or 0\n   1371 \n   1372             maybe_callable = com._apply_if_callable(key, self.obj)\n-> 1373             return self._getitem_axis(maybe_callable, axis=axis)\n        self._getitem_axis = <bound method _iLocIndexer._getitem_axis of <pandas.core.indexing._iLocIndexer object>>\n        maybe_callable = array([   0,    1,    2, ..., 5564, 5565, 5566])\n        axis = 0\n   1374 \n   1375     def _is_scalar_access(self, key):\n   1376         raise NotImplementedError()\n   1377 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self=<pandas.core.indexing._iLocIndexer object>, key=array([   0,    1,    2, ..., 5564, 5565, 5566]), axis=0)\n   1814             self._has_valid_type(key, axis)\n   1815             return self._getbool_axis(key, axis=axis)\n   1816 \n   1817         # a list of integers\n   1818         elif is_list_like_indexer(key):\n-> 1819             return self._get_list_axis(key, axis=axis)\n        self._get_list_axis = <bound method _iLocIndexer._get_list_axis of <pandas.core.indexing._iLocIndexer object>>\n        key = array([   0,    1,    2, ..., 5564, 5565, 5566])\n        axis = 0\n   1820 \n   1821         # a single integer\n   1822         else:\n   1823             key = self._convert_scalar_indexer(key, axis)\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py in _get_list_axis(self=<pandas.core.indexing._iLocIndexer object>, key=array([   0,    1,    2, ..., 5564, 5565, 5566]), axis=0)\n   1789         Series object\n   1790         \"\"\"\n   1791         if axis is None:\n   1792             axis = self.axis or 0\n   1793         try:\n-> 1794             return self.obj._take(key, axis=axis, convert=False)\n        self.obj._take = <bound method NDFrame._take of       body_len  p...000000   0.0   0.0  \n\n[5567 rows x 8106 columns]>\n        key = array([   0,    1,    2, ..., 5564, 5565, 5566])\n        axis = 0\n   1795         except IndexError:\n   1796             # re-raise with different error message\n   1797             raise IndexError(\"positional indexers are out-of-bounds\")\n   1798 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in _take(self=      body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], indices=array([   0,    1,    2, ..., 5564, 5565, 5566]), axis=0, convert=False, is_copy=True)\n   2138         numpy.take\n   2139         \"\"\"\n   2140 \n   2141     @Appender(_shared_docs['_take'])\n   2142     def _take(self, indices, axis=0, convert=True, is_copy=True):\n-> 2143         self._consolidate_inplace()\n        self._consolidate_inplace = <bound method NDFrame._consolidate_inplace of   ...000000   0.0   0.0  \n\n[5567 rows x 8106 columns]>\n   2144 \n   2145         if convert:\n   2146             indices = maybe_convert_indices(indices, len(self._get_axis(axis)))\n   2147 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in _consolidate_inplace(self=      body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns])\n   3672         \"\"\"Consolidate data in place and return None\"\"\"\n   3673 \n   3674         def f():\n   3675             self._data = self._data.consolidate()\n   3676 \n-> 3677         self._protect_consolidate(f)\n        self._protect_consolidate = <bound method NDFrame._protect_consolidate of   ...000000   0.0   0.0  \n\n[5567 rows x 8106 columns]>\n        f = <function NDFrame._consolidate_inplace.<locals>.f>\n   3678 \n   3679     def _consolidate(self, inplace=False):\n   3680         \"\"\"\n   3681         Compute NDFrame with \"consolidated\" internals (data of each dtype\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in _protect_consolidate(self=      body_len  punct%         0    1    2    3 ....000000   0.0   0.0  \n\n[5567 rows x 8106 columns], f=<function NDFrame._consolidate_inplace.<locals>.f>)\n   3661     def _protect_consolidate(self, f):\n   3662         \"\"\"Consolidate _data -- if the blocks have changed, then clear the\n   3663         cache\n   3664         \"\"\"\n   3665         blocks_before = len(self._data.blocks)\n-> 3666         result = f()\n        result = undefined\n        f = <function NDFrame._consolidate_inplace.<locals>.f>\n   3667         if len(self._data.blocks) != blocks_before:\n   3668             self._clear_item_cache()\n   3669         return result\n   3670 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in f()\n   3670 \n   3671     def _consolidate_inplace(self):\n   3672         \"\"\"Consolidate data in place and return None\"\"\"\n   3673 \n   3674         def f():\n-> 3675             self._data = self._data.consolidate()\n   3676 \n   3677         self._protect_consolidate(f)\n   3678 \n   3679     def _consolidate(self, inplace=False):\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py in consolidate(self=BlockManager\nItems: Index(['body_len',   'punct%...k: slice(2, 8106, 1), 8104 x 5567, dtype: float64)\n   3821         if self.is_consolidated():\n   3822             return self\n   3823 \n   3824         bm = self.__class__(self.blocks, self.axes)\n   3825         bm._is_consolidated = False\n-> 3826         bm._consolidate_inplace()\n        bm._consolidate_inplace = <bound method BlockManager._consolidate_inplace ...: slice(2, 8106, 1), 8104 x 5567, dtype: float64>\n   3827         return bm\n   3828 \n   3829     def _consolidate_inplace(self):\n   3830         if not self.is_consolidated():\n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py in _consolidate_inplace(self=BlockManager\nItems: Index(['body_len',   'punct%...k: slice(2, 8106, 1), 8104 x 5567, dtype: float64)\n   3826         bm._consolidate_inplace()\n   3827         return bm\n   3828 \n   3829     def _consolidate_inplace(self):\n   3830         if not self.is_consolidated():\n-> 3831             self.blocks = tuple(_consolidate(self.blocks))\n        self.blocks = (IntBlock: slice(0, 1, 1), 1 x 5567, dtype: int64, FloatBlock: slice(1, 2, 1), 1 x 5567, dtype: float64, FloatBlock: slice(2, 8106, 1), 8104 x 5567, dtype: float64)\n   3832             self._is_consolidated = True\n   3833             self._known_consolidated = True\n   3834             self._rebuild_blknos_and_blklocs()\n   3835 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py in _consolidate(blocks=(IntBlock: slice(0, 1, 1), 1 x 5567, dtype: int64, FloatBlock: slice(1, 2, 1), 1 x 5567, dtype: float64, FloatBlock: slice(2, 8106, 1), 8104 x 5567, dtype: float64))\n   4848     grouper = itertools.groupby(sorted(blocks, key=gkey), gkey)\n   4849 \n   4850     new_blocks = []\n   4851     for (_can_consolidate, dtype), group_blocks in grouper:\n   4852         merged_blocks = _merge_blocks(list(group_blocks), dtype=dtype,\n-> 4853                                       _can_consolidate=_can_consolidate)\n        _can_consolidate = True\n   4854         new_blocks = _extend_blocks(merged_blocks, new_blocks)\n   4855     return new_blocks\n   4856 \n   4857 \n\n...........................................................................\n/home/bmacs/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py in _merge_blocks(blocks=[FloatBlock: slice(1, 2, 1), 1 x 5567, dtype: float64, FloatBlock: slice(2, 8106, 1), 8104 x 5567, dtype: float64], dtype='float64', _can_consolidate=True)\n   4871         # combination of those slices is a slice, too.\n   4872         new_mgr_locs = np.concatenate([b.mgr_locs.as_array for b in blocks])\n   4873         new_values = _vstack([b.values for b in blocks], dtype)\n   4874 \n   4875         argsort = np.argsort(new_mgr_locs)\n-> 4876         new_values = new_values[argsort]\n        new_values = array([[  4.7,   4.1,   3.2, ...,  14.6,   1. , ...[  0. ,   0. ,   0. , ...,   0. ,   0. ,   0. ]])\n        argsort = array([   0,    1,    2, ..., 8102, 8103, 8104])\n   4877         new_mgr_locs = new_mgr_locs[argsort]\n   4878 \n   4879         return make_block(new_values, fastpath=True, placement=new_mgr_locs)\n   4880 \n\nMemoryError: \n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "cross_val_score(rf, X_features, data['label'], cv=k_fold, scoring='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
